{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python==4.6.0.66\n",
    "#!pip install mediapipe==0.8.11\n",
    "#!pip install mediapipe --user\n",
    "#!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_olho_esq = [385, 380, 387, 373, 362, 263]\n",
    "p_olho_dir = [160, 144, 158, 153, 33, 133]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[385, 380, 387, 373, 362, 263, 160, 144, 158, 153, 33, 133]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_olhos = p_olho_esq + p_olho_dir\n",
    "p_olhos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_boca = [82, 87, 13, 14, 312, 317, 78, 308]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculo_mar(face,p_boca):\n",
    "    try:\n",
    "        face= np.array([[coord.x,coord.y]for coord in face])\n",
    "        face_boca = face[p_boca,:]\n",
    "        mar = (np.linalg.norm(face_boca[0]-face_boca[1])+(np.linalg.norm(face_boca[2]-face_boca[3]))+ (np.linalg.norm(face_boca[4]-face_boca[5])))/(2*(np.linalg.norm(face_boca[6]-face_boca[7])))\n",
    "    except:\n",
    "        mar = 0.0\n",
    "    \n",
    "    return  mar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculo_ear(face, p_olho_dir,p_olho_esq):\n",
    "    try:\n",
    "        face = np.array([[coord.x, coord.y] for coord in face])\n",
    "        face_esq = face[p_olho_esq,:]\n",
    "        face_dir = face[p_olho_dir,:]\n",
    "\n",
    "        ear_esq = (np.linalg.norm(face_esq[0]-face_esq[1])+np.linalg.norm(face_esq[2]-face_esq[3]))/(2*(np.linalg.norm(face_esq[4]-face_esq[5])))\n",
    "        ear_dir = (np.linalg.norm(face_dir[0]-face_dir[1])+np.linalg.norm(face_dir[2]-face_dir[3]))/(2*(np.linalg.norm(face_dir[4]-face_dir[5])))\n",
    "    except:\n",
    "        ear_esq = 0.0\n",
    "        ear_dir = 0.0\n",
    "    media_ear = (ear_esq+ear_dir)/2\n",
    "    return media_ear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n",
      "'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "ear_limiar = 0.34\n",
    "dormindo = 0\n",
    "mar_limiar = 0.30\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as facemesh:\n",
    "    while cap.isOpened():\n",
    "        sucesso, frame = cap.read()\n",
    "        if not sucesso:\n",
    "            print('Ignorando o frame vazio da cÃ¢mera.')\n",
    "            continue\n",
    "        comprimento, largura, _ = frame.shape\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        saida_facemesh = facemesh.process(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        try:\n",
    "            for face_landmarks in saida_facemesh.multi_face_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                    landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 102, 102), thickness=1, circle_radius=1),\n",
    "                    connection_drawing_spec=mp_drawing.DrawingSpec(color=(102, 204, 0), thickness=1, circle_radius=1))\n",
    "                face = face_landmarks.landmark\n",
    "                for id_coord, coord_xyz in enumerate(face_landmarks.landmark):\n",
    "                    if id_coord in p_olhos:\n",
    "                        coord_cv = mp_drawing._normalized_to_pixel_coordinates(coord_xyz.x, coord_xyz.y, largura, comprimento)\n",
    "                        cv2.circle(frame, coord_cv, 2, (255, 0, 0), -1)\n",
    "                    if id_coord in p_boca:\n",
    "                        coord_cv = mp_drawing._normalized_to_pixel_coordinates(coord_xyz.x, coord_xyz.y, largura, comprimento)\n",
    "                        cv2.circle(frame, coord_cv, 2, (255, 0, 0), -1)\n",
    "                           \n",
    "                ear = calculo_ear(face,p_olho_dir ,p_olho_esq)\n",
    "                cv2.rectangle(frame, (0,1),(290,140),(58,58,55),-1)\n",
    "                cv2.putText(frame, f\"EAR: {round(ear, 2)}\", (1, 24),\n",
    "                                cv2.FONT_HERSHEY_DUPLEX,\n",
    "                                0.9, (255, 255, 255), 2)\n",
    "                mar = calculo_mar(face,p_boca)\n",
    "                \n",
    "                cv2.putText(frame, f\"MAR: {round(mar, 2)} {'Aberto' if mar >= mar_limiar else'Fechado'}\", (1, 50),\n",
    "                                cv2.FONT_HERSHEY_DUPLEX,\n",
    "                                0.9, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "                if ear < ear_limiar:\n",
    "                    t_inicial = time.time() if dormindo == 0 else t_inicial\n",
    "                    dormindo = 1\n",
    "                if (dormindo == 1 and ear >= ear_limiar) or (ear <= ear_limiar and mar>=mar_limiar):\n",
    "                    dormindo = 0      \n",
    "                t_final = time.time() \n",
    "                \n",
    "                tempo = (t_final-t_inicial) if dormindo == 1 else 0.0\n",
    "                cv2.putText(frame, f\"Tempo: {round(tempo, 3)}\", (1, 80),\n",
    "                                        cv2.FONT_HERSHEY_DUPLEX,\n",
    "                                        0.9, (255, 255, 255), 2)\n",
    "                if tempo >= ear_limiar and mar<mar_limiar :\n",
    "                    cv2.rectangle(frame, (30, 400), (610, 452), (109, 233, 219), -1)\n",
    "                    cv2.putText(frame, f\"Muito tempo com olhos fechados!\", (80, 435),\n",
    "                                    cv2.FONT_HERSHEY_DUPLEX,\n",
    "                                    0.85, (58,58,55), 1)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "        cv2.imshow('Camera', frame)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('c'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'saida_facemesh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m saida_facemesh\u001b[38;5;241m.\u001b[39mmulti_face_landmarks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m face_landmarks \u001b[38;5;129;01min\u001b[39;00m saida_facemesh\u001b[38;5;241m.\u001b[39mmulti_face_landmarks:\n\u001b[0;32m      3\u001b[0m         face \u001b[38;5;241m=\u001b[39m face_landmarks\n",
      "\u001b[1;31mNameError\u001b[0m: name 'saida_facemesh' is not defined"
     ]
    }
   ],
   "source": [
    "if saida_facemesh.multi_face_landmarks is not None:\n",
    "    for face_landmarks in saida_facemesh.multi_face_landmarks:\n",
    "        face = face_landmarks\n",
    "        for id_coord, coord_xyz in enumerate(face.landmark):\n",
    "            print(id_coord)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
